---
title: "Projekt"
date: "20 nov 2019"
output: html_document
---
# An introduction to image classification for multiple classes using CNN and ResNet

## Image classification for multiple classes

In this project, we are focusing on dealing with image classification, which refers to a process in computer vision that can classify an image according to its visual content. Over the last years, it has grown effective due to it using deep learning. Deep learning is a class of machine learning that uses multiple layers to extract higher level features. Some expamples on its usage are Face Recognition on social platforms like Facebook or Product Discoverability which allows consumers to search for similar images or products.  

Keras has 10 pretrained models, for example VGG16 and ResNet50, which are trained on ImageNet, a large collection of images in 1000 classes. An image classifier contains convolutional and fully conncted layers. The convolutional layers extract features and fully conncted classify them using the features. 


## The data set
In this project we're making a guide on image classification in R. We're working with the Fruit data set from Kaggle, found on https://www.kaggle.com/moltean/fruits/data. Here 120 different fruits and vegetables are stored in different classes. The data set has 82213 images of fruit and vegetables. The data set is split into a training set containing 61488 images and a test set containing 20622 images. The images sizes are 100x100 pixels. 

In the data set there was a difference in lighting conditions, the background was not uniform and beforehand there has been written a dedicated algorithm which extracts the fruit from the background, so the fruit and vegetables are seen on the images with a white background.

## An example using CNN

### Load the data
We start by cleaning the global environment. 

```{r}
#Cleaning the environment
rm(list=ls())
```

And then we'll import Keras, which is essential for the anaysis. You have to use "install_keras" if you're installing Keras for the first time.

```{r}
devtools::install_github("rstudio/keras", force = TRUE)
library(keras)
#install_keras()
```

And then we'll load a bunch of other packages.

```{r, include=FALSE}
#Loading packages
if (!require("pacman")) install.packages("pacman") # package for loading and checking packages :)
pacman::p_load(knitr, # For knitr to html
               rmarkdown, # For formatting the document
               tidyverse, # Standard datasciewnce toolkid (dplyr, ggplot2 et al.)
               data.table, # for reading in data ect. 
               magrittr,# For advanced piping (%>% et al.)
               igraph, # For network analysis
               tidygraph, # For tidy-style graph manipulation
               ggraph, # For ggplot2 style graph plotting
               Matrix, # For some matrix functionality
               ggforce, # Awesome plotting
               kableExtra, # Formatting for tables
               car, # recode functions 
               tidytext, # Structure text within tidyverse
               topicmodels, # For topic modelling
               tm, # text mining library
               quanteda, # for LSA (latent semantic analysis)
               uwot, # for UMAP
               dbscan, # for density based clustering
               SnowballC,
               textdata,
               wordcloud, 
               textstem, # for textstemming 
               tidyr,
               widyr,
               reshape2,
               quanteda,
               uwot,
               dbscan,
               plotly,
               rsample,
               glmnet,
               broom,
               yardstick,
               lda, # For LDA-analysis
               topicmodels, # LDA models
               broom,
               keras,
               drat,
               reticulate,
               BiocManager
               )
```


### Preprocessing 

And then we can load the data the data from Kaggle. We just loaded it locally

```{r}
train_images = "/Users/Emma/OneDrive/Universitetet/9. semester/SDS/M3/fruits-360_dataset/fruits-360/Training/"

test_images = "/Users/Emma/OneDrive/Universitetet/9. semester/SDS/M3/fruits-360_dataset/fruits-360/Test/"
```


Then we need to define a vector of the fruits and vegetables we want to train our model to classify, as we're not going to train it to classify 120. At the same time we also define some variabels to scale down the picture - which original is 100 x 100pixel.

```{r}
FV_list <- c("Quince","Tangelo","Walnut","Physalis","Pepino","Orange","Blueberry","Mulberry","Kaki", "Guava","Eggplant","Carambula","Beetroot","Apricot","Avocado")

length <- length(FV_list)

```

Then we're using the function "image_data_generator", which can load and generate batches of the image data. Here we're first rescaling the image data. For most image data, the pixel values are integers with values between 0 and 255, which is why dividing the data with 255. This is performed across all channels, regardless of the actual range of pixel values that are present in the images. Here we're also applying zoom range, which is the amount of zoom. We're also rescaling the test data set

```{r}
train_images = "C:/Users/Michael Thomsen/Desktop/fruits-360_dataset/fruits-360/Training/"

test_images = "C:/Users/Michael Thomsen/Desktop/fruits-360_dataset/fruits-360/Test/"
```

```{r}
train_images_rescale = image_data_generator(rescale = 1/255)

test_images_rescale = image_data_generator(rescale = 1/255)
```

We now want to load our images into the memory and resize them. To do this the 'flow_images_from_directory' function from the Keras package will come in use. It allows us to generate batches of data from images in a directory. We start by setting the 'class_mode' to categorical, due to the data list we created earlier. The same applies for the which 'classes', we are refering back to. At last we the set the seed to 123, as it allows us to reproduce the same results later.


```{r}
# training images
train_image_array <- flow_images_from_directory(train_images, 
                                                    train_images_rescale,
                                                    target_size = c(64,64),
                                                    class_mode = "categorical",
                                                    classes = FV_list)

# validation images
test_image_array <- flow_images_from_directory(test_images, 
                                                    test_images_rescale,
                                                    target_size = c(64,64),
                                                    class_mode = "categorical",
                                                    classes = FV_list)  
```

We can now explore how many images we have in each of our list of fruits.

```{r}
cat("Number of images per class:")
table(factor(train_image_array$classes))
```

As the table show, there is a nice distrubtion of number of images in every classes. That's good so we dont have a group of classes which is over represented over others classes.


# Defining the model

Now it's time to set up the model, that should be able to predict the images. To start of we will define the number of training and testing samples, aswell as the batch_size and epochs.
##Epochs
The number of epochs for training indicates, which amount of times the the model will expose itself to the whole training set.
##Batch size
The batch size indicates the number of sequences to look at one at time during training. It's advice to do choose the number that matches with the power of two, due to then you train the model on the GPU.

We are now ready for creating a model. We'll start of with a simple Convolutional Neural Net (CNN) model. It will contain the following layers: 2 Convolutional, 1 Pooling and 1 Dense.
The first thing is to use the 'keras_model_sequential' function which allows us to composing a model with diffrent kind of linear layers.

```{r}
model <- keras_model_sequential()


model %>%
  layer_conv_2d(filter = 32, kernel_size = c(3,3), padding = "same", input_shape = c(64,64, 3), activation = "relu") %>%
  layer_conv_2d(filter = 16, kernel_size = c(3,3), padding = "same") %>%
  layer_activation_leaky_relu(0.5) %>%
  layer_batch_normalization() %>%
  layer_max_pooling_2d(pool_size = c(2,2)) %>%
  layer_dropout(0.25) %>%
  layer_flatten() %>%
  layer_dense(100, activation = "relu") %>%
  layer_dropout(0.5) %>%
  layer_dense(length, activation = "softmax")
```

```{r}
# compile
model %>% compile(
  loss = "categorical_crossentropy",
  optimizer = "adam",
  metrics = "accuracy"
)
```

```{r}
hist <- model %>% fit_generator(train_image_array,
  steps_per_epoch = 100, 
  epochs = 10, 
  validation_data = test_image_array,
  validation_steps = 100
)
```


# Pretrained model


```{r}
resnet50 = keras::application_resnet50(weights = NULL)
```

```{r}
summary(resnet50)
```

```{r}
freeze_weights(resnet50, from = 1, to = 48)
```

```{r}
model = keras_model_sequential(resnet50)
```

```{r}
model = model %>% layer_dense(units = 16, activation = "sigmoid")
```

```{r}
dim(model)
```


```{r}
summary(model)
```


```{r}
model %>% compile(
  optimizer = "rmsprop",
  loss = "categorical_crossentropy",
  metrics = "accuracy"
)
```



```{r}
history = model %>% fit_generator(
  training_set,
  epochs = 10,
  steps_per_epoch = 100,
  validation_data = test_set,
  validation_steps = 100
)
```

